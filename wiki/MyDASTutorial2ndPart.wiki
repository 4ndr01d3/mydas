#summary Tutorial for MyDAS - Intermediate level
#labels Phase-Support
= MyDAS 1.6 Tutorial =

== Second Part: Developing your own Data Source ==
Now that you have been a real DAS source working on MyDAS lets get closer to a more interesting example: what if you have your data in an in-house format? and therefore the templates/examples don't apply for your data source?

Following this tutorial you will parse an in-house formated file, publish its information as a data source in MyDAS using the DAS command feature. You can used the IDE of your choice but the tutorial is done in such a way you can use just a terminal and a text editor.

=== Example File ===
The file of this example was built using information from the ensembl database homo_sapiens_core_56_37a. The file gives positional information of genes, transcripts and exons in the chromosome 5 organized in a separated by pipes `|` like this:
{{{
|chr|gene_id|gene_start|gene_end|trascript_id|transcript_start|transcript_end|exon_id|exon_start|exon_end|
}}}
You can see a sample of this file below.
{{{
|5|ENSG00000153404|140373|190087|ENST00000398036|140373|157131|ENSE00001648483|156888|157131|
|5|ENSG00000153404|140373|190087|ENST00000398036|140373|157131|ENSE00001135995|156186|156325|
|5|ENSG00000153404|140373|190087|ENST00000398036|140373|157131|ENSE00001136002|155460|155558|
|5|ENSG00000153404|140373|190087|ENST00000398036|140373|157131|ENSE00001136007|154990|155106|
|5|ENSG00000153404|140373|190087|ENST00000398036|140373|157131|ENSE00001136016|151628|151714|
|5|ENSG00000153404|140373|190087|ENST00000398036|140373|157131|ENSE00001136025|144942|145035|
|5|ENSG00000153404|140373|190087|ENST00000398036|140373|157131|ENSE00001136029|143495|143618|
}}}


=== Analyzing the Data ===
Firstly, we know from this file the information that our data source has to provide and from them that there will be just four types of features in this data source:
  * chromosome: In our example will be always the same(5) however we can create our source to support files with information from more than one chromosome. This type should look in DAS like: 
{{{ 
<TYPE id="Chromosome" cvId="SO:0000340">Chromosome</TYPE> 
}}}
  * genes: The file give us information about the start and end of the genes plus its ID. From there we have another type in our data source:
{{{
<TYPE id="Gene" cvId="SO:0000704">Gene</TYPE>
}}}
  But also we have the id field of each feature of this type and the tags start and end can be also deduced from there.
  * transcripts: As in the case of genes the information provided is the id, start and stop. So we will need a new DAS type:
{{{
<TYPE id="Transcript" cvId="SO:0000673">Transcript</TYPE>
}}}
  * exons: Same analysis as above:
{{{
<TYPE id="Exon" cvId="SO:0000147">Exon</TYPE>
}}}
Note that the numbers at cvId are valid Ontology Ids from the Sequence Ontology.

The other information that we have implicit in this file is that there is a hierarchy in those components. A chromosome contains genes, a gene contains transcripts, an transcript contains exons. 

For this demo we can assume some values for all the annotations, the method will be
{{{
<METHOD id="not_recorded" cvId="ECO:0000037">not_recorded</METHOD> 
}}}
And given that we don't know the score, phase and orientation, we will assume those values as not applicable.

=== Implementing the Data Source ===
Now lets go to work.  The task of implementing the data source can be divided in three parts:
  # Implement a parser of the file.
  # Implement one of the MyDAS Data Sources Interfaces.
  # Configure MyDAS with the new Data Source.

Something to consider before to start is the strategy to deal with the data. It means if  the file is gonna be parsed completely and keep it in memory as a model (As the gff example) or if the file will be processed every time something is requested.

Pros and cons? the whole file in memory will response quicker but the bigger the file, the most memory the system will require. Opposite situation with the other case; processing the file for each request doesn't require too much memory, but the response time will be proportional to the size of the file.

Maybe an intermediate approach with a preprocessing stage, and subsequents specialized processes per query, can be a better way, however it will require to focus in details that are not in the scope of this tutorial.

The approach to follow here will be parsing the file and keeping a model in memory. It is quite similar to the one used for the gff example, so you might one to have a look on the files on `[MyDasTemplate]/src/main/java/uk/ac/ebi/mydas/examples/` before to start coding.

So, lets start coding a parser for this file. The goal of the parser is to get the info loaded in memory using the model of MyDAS to represent segments an annotations.

==== Implement a parser of the file ====
  # Create a file in `[MyDasTemplate]/src/main/java/uk/ac/ebi/mydas/examples/` called `SeparatedByPipesParser.java` and opened to edit with the editor of your choice(vi, write, eclipse, intelliJ, etc.)


<div class="NavFrame">
  <div class="NavHead">[... This is the title of your collapsible content ...]</div>
  <div class="NavContent">
    [... The content you want to hide goes here ...]
  </div>
</div>